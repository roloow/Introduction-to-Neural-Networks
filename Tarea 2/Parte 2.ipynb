{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2 CNNs en Google Street View\n",
    "\n",
    "En esta sección, trabajaremos con el dataset **SVHN** (Street View House Numbers), correspondiente a imágenes naturales de dígitos de direcciones obtenidos desde Google Street View. El dataset contiene más de 600.000 imágenes de entrenamiento y 26.032 imágenes de test. Para facilitar la realización de experimentos, el dataset de entrenamiento se divide usualmente en un conjunto pequeño de 73.257 imágenes y un conjunto “*extra*” de 531.131 imágenes. En esta tarea trabajaremos sólo con la versión pequeña. Los valientes pueden veriﬁcar que entrenando sobre el conjunto grande los resultados mejoran signiﬁcativamente.\n",
    "\n",
    "Los datos pueden ser obtenidos (en formato Matlab) ejecutando los siguientes comandos:\n",
    "\n",
    "```\n",
    "wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat \n",
    "wget http://ufldl.stanford.edu/housenumbers/extra_32x32.mat\n",
    "wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
    "\n",
    "```\n",
    "\n",
    "## A. Conocer el DataSet\n",
    "\n",
    "Cargue los datos de entrenamiento y pruebas (“*train 32x32.mat*” y “*test 32x32.mat*”). Determine el tamaño de las imágenes, el número de clases diferentes y de ejemplos en cada categoría. Finalmente, visualice 5 imágenes de entrenamiento y 5 de test (elegidas aleatoriamente). Comente.\n",
    "\n",
    "```python\n",
    "1 import scipy.io as sio \n",
    "2 import numpy as np \n",
    "3 train_data = sio.loadmat('train_32x32.mat') \n",
    "4 test_data = sio.loadmat('test_32x32.mat') \n",
    "5 X_train = train_data['X'].T \n",
    "6 y_train = train_data['y'] - 1 \n",
    "7 X_test = test_data['X'].T \n",
    "8 y_test = test_data['y'] - 1 \n",
    "9 X_train = X_train.astype('float32') \n",
    "10 X_test = X_test.astype('float32') \n",
    "11 n_classes = len(np.unique(y_train)) \n",
    "12 print np.unique(y_train)\n",
    "```\n",
    "\n",
    "## B. Normalización de datos\n",
    "\n",
    "Normalice las imágenes, dividiendo las intensidades originales de pixel por 255. Represente adecuadamente la salida deseada de la red de modo de tener un vector de tamaño igual al número de clases.\n",
    "\n",
    "```python\n",
    "1 from keras.utils import np_utils \n",
    "2 X_train /= 255 \n",
    "3 X_test /= 255 \n",
    "4 Y_train = np_utils.to_categorical(y_train, n_classes) \n",
    "5 Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "```\n",
    "\n",
    "## C. Definir una red convolucional\n",
    "\n",
    "Deﬁna una CNN con arquitectura C×P×C×P×F×F. Para la primera capa convolucional utilice 16 ﬁltros de 5×5 y para la segunda 512 ﬁltros de 7×7. Para la capa MLP escondida use 20 neuronas. Esta arquitectura, con algunas diferencias, fue una de las primera CNNs entrenadas sobre SVHN y consiguió una accuracy de 94.28%. Genere un esquema lo más compacto posible que muestre los cambios de forma que experimenta un patrón de entrada a medida que se ejecuta un forward-pass. Entrene la red anterior un máximo de 10 epochs. ¿Logra mejorar o al menos igualar el resultado reportado en la literatura?\n",
    "\n",
    "```python\n",
    "1 from keras.models import Sequential \n",
    "2 from keras.layers.core import Dense, Dropout, Activation, Flatten \n",
    "3 from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D \n",
    "4 from keras.optimizers import SGD, Adadelta, Adagrad \n",
    "5 model = Sequential() \n",
    "6 model.add(Convolution2D(16, 5, 5, border_mode='same', activation='relu', \n",
    "7                                 input_shape=(n_channels, n_rows, n_cols))) \n",
    "8 model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "9 model.add(Convolution2D(512, 7, 7, border_mode='same', activation='relu')) \n",
    "10 model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "11 model.add(Flatten()) \n",
    "12 model.add(Dense(20, activation='relu')) \n",
    "13 model.add(Dense(n_classes, activation='softmax')) \n",
    "14 model.summary() \n",
    "15 model.compile(loss='categorical_crossentropy', optimizer=adagrad, metrics=['accuracy']) \n",
    "16 adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0) \n",
    "17 model.fit(X_train, Y_train, batch_size=1280, nb_epoch=12, verbose=1, \\ \n",
    "18                                             validation_data=(X_test, Y_test))\n",
    "```\n",
    "\n",
    "## D. Modificar tamaño de los filtros\n",
    "\n",
    "Evalúe el efecto de modiﬁcar el tamaño de los ﬁltros (de convolución y pooling) reportando la sensibilidad del error de pruebas a estos cambios. Presente un gráﬁco o tabla resumen. Por simplicidad entre durante sólo 10 epochs.\n",
    "\n",
    "## E. Modificar número de filtros\n",
    "\n",
    "Evalúe el efecto de modiﬁcar el número de ﬁltros para las capas convolucionales tanto en los tiempos de entrenamiento como en el desempeño de la red. Presente un gráﬁco o tabla resumen. Por simplicidad entre durante sólo 10 epochs.\n",
    "\n",
    "## F. Propuesta de mejora\n",
    "\n",
    "Proponga una mejora sobre la red deﬁnida en (**c**) que mejore el error de pruebas. Recuerde que debe deﬁnir un subconjunto de validación si necesita elegir entre arquitecturas. \n",
    "\n",
    "## G. Visualizacion de pesos y efectos del filtro\n",
    "\n",
    "Elija una de las redes entrenadas (preferentemente una con buen desempeño) y visualice los pesos correspondientes a los ﬁltros de la primera capa convolucional. Visualice además el efecto del ﬁltro sobre algunas imágenes de entrenamiento. Comente.\n",
    "\n",
    "## H. Determinar dígitos confusos para la red\n",
    "\n",
    "Elija una de las redes entrenadas en esta sección y determine los pares de dígitos (por ejemplo “1” con “7”) que la red tiende a confundir. Conjeture el motivo de tal confusión.\n",
    "\n",
    "\n",
    "## I. Evaluación de convenencia\n",
    "\n",
    "(Opcional, Bonus +10 en certamen) Evalúe la conveniencia de utilizar todo el dataset (“extra 32x32.mat”) en el entrenamiento de la red.\n",
    "\n",
    "------------------------\n",
    "\n",
    "# Desarrollo\n",
    "\n",
    "Para el desarrollo de esta pregunta se utilizó un código fuente que se encuentra en la carpeta scripts. El archivo lleva el mismo nombre [scripts.py](https://github.com/roloow/Redes-Neuronales/blob/master/Tarea%202/Scripts/Parte%202/scripts.py)\n",
    "\n",
    "## A)\n",
    "\n",
    "Mediante la utilización de la función *.shape* podemos obtener como últimos dos resultados, las dimensiones de cada elemento. Aún cuando esto sea evidente dado que bajamos un formato *32x32* Además las clases obtenidas en el conjunto **y** pueden ser enumeradas mediante la función *unique()* de **numpy**, lo que genera una lista de todas las clases distintas y luego basta con obtener el largo de la lista para saber la cantidad de estos.\n",
    "\n",
    "> Tamaño de las imagenes: 32x32\n",
    "\n",
    "> Número de clases: 10\n",
    "\n",
    "Luego para ver las imagenes se utiliza la clásica librería de **matplotlib** pero utilizando la funcionalidad *implot()*. Entonces, se toma un conjunto aleatoreo de ambos grupos. **NOTAR** por temas de memoria, el cambio *astype*, se deja de lado por el momento..\n",
    "\n",
    "```python\n",
    "TRAIN_EXAMPLES = random.sample(list(X_train), IMG_NUM)\n",
    "```\n",
    "<img src=\"Scripts/Parte2/5im_entrenamiento.png\" style=\"width: 500px;\"/>\n",
    "```python\n",
    "TEST_EXAMPLES = random.sample(list(X_test), IMG_NUM)\n",
    "```\n",
    "<img src=\"Scripts/Parte2/5im_test.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "### Comentarios\n",
    "\n",
    "El uso del transpose se hace, dado que se intento realizar un reshape antes de ejecutarlo, pero existía una variable 32 que quedaba inmovil lo que seguía dejando la imagen ladeada por lo que se decidió utilizar la propiedad *transpose* para reordenar literalmente el conjunto.\n",
    "\n",
    "## B)\n",
    "\n",
    "Se realizan los pasos pedidos, sin embargo **Python 2.7** en **Windows** tiene restringido el uso de memoria para los procesos del mismo, por esto utilizar *float32* fue radicalmente imposible, aún cuando teníamos una CPU con 16GB de RAM. Dada la premisa anterior se tuvo que cambiar a *float16*.\n",
    "\n",
    "```python\n",
    "X_train = X_train.astype('float16') \n",
    "X_test = X_test.astype('float16') \n",
    "```\n",
    "\n",
    "## C)\n",
    "\n",
    "En primera instancia se crea el modelo y se genera una tabla de contenidos, que básicamente realiza un resumen de las capas y sus salidas.\n",
    "\n",
    "<center>\n",
    "```\n",
    "|-----------------------------|-------------------|----------|\n",
    "| Layer (type)                | Output Shape      | Param #  |\n",
    "|-----------------------------|-------------------|----------|\n",
    "|conv2d_1 (Conv2D)            |(None, 16, 32, 32) |1216      |\n",
    "|max_pooling2d_1 (MaxPooling2)|(None, 16, 16, 16) |0         |\n",
    "|conv2d_2 (Conv2D)            |(None, 512, 16, 16)|401920    |\n",
    "|max_pooling2d_2 (MaxPooling2)|(None, 512, 8, 8)  |0         |\n",
    "|flatten_1 (Flatten)          |(None, 32768)      |0         |\n",
    "|dense_1 (Dense)              |(None, 20)         |655380    |\n",
    "|dense_2 (Dense)              |(None, 10)         |210       |\n",
    "```\n",
    "</center>\n",
    "\n",
    "> Total params: 1,058,726\n",
    "\n",
    "> Trainable params: 1,058,726\n",
    "\n",
    "> Non-trainable params: 0\n",
    "\n",
    "Con esto modelado, se pasa a entrenar la red con una función de perdida **categorical** y un optimizador *Agradad* definido por\n",
    "```python\n",
    "Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "```\n",
    "Esto con la inclusión de la GPU a **Theano** mediante un archivo *.theanorc* permitió correr el entrenamiento dado que de otra forma, este se veía detenido al llegar a un punto que dejaba a la CPU sin memoria.\n",
    "\n",
    "La primera epoch:\n",
    "> Epoch 1/10  |  73257/73257 [==============================] - 617s\n",
    "\n",
    "> **loss**: 0.2681 - **acc**: 0.9126 - **val_loss**: 0.2033 - **val_acc**: 0.9332\n",
    "\n",
    "Mientras que en la última\n",
    "> Epoch 10/10 |  73257/73257 [==============================] - 398s\n",
    "\n",
    "> **loss**: 0.0583 - **acc**: 0.9842 - **val_loss**: 0.0926 - **val_acc**: 0.9806\n",
    "\n",
    "En la literatura se habla de un *Accuracy* de *94.28* **%**, y si bien nuestra red convolucional parte siendo inferior a lo leido, tras el entrenamiento supera con amplia diferencia lo esperado.\n",
    "\n",
    "Luego para poder ver mejor como evoluciona la red se graficó la perdida con respecto a los ciclos de entrenamiento.\n",
    "\n",
    "<img src=\"Scripts/Parte2/loss.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "## D)\n",
    "\n",
    "Para este caso se utilizó el mismo código de la parte **C**, solo que los valores alterados haciendo referencia al código anterior, fueron las tuplas (5,5) y (7,7) para la modificación convolucional y los valores del *pool_size* para la modificación pooling.\n",
    "\n",
    "Debido a que los números anteriores tenian una cierta correlación decidimos mantenerla, siendo las tuplas números impares y los pool_size números pares. Como probaremos un producto cruz de estos elementos, es decir *CxP* con 3 tuplas y 2 pooling generamos 6 resultados los que son suficientes para analizar.\n",
    "\n",
    "> CONV = [(5,5), (7,7), (9,9)]\n",
    "\n",
    "> POOL = [(2,2), (4,4)]\n",
    "\n",
    "A continuación se presentan de la siguiente forma, los resultados de los errores, un gráfico individual, un gráfico comparativo con los mismos *pool_size* y un gráfico comparativo entre todos. **NOTAR** que al reemplazar por el valor *7* las convoluciones y con *2* de pooling generó un resultado invariante.\n",
    "\n",
    "#### Convolucion: 5 - Pool Size: 2\n",
    "<img src=\"Scripts/Parte2/52.png\" style=\"width: 300px;\"/>\n",
    "#### Convolucion: 5 - Pool Size: 4\n",
    "<img src=\"Scripts/Parte2/54.png\" style=\"width: 300px;\"/>\n",
    "#### Convolucion: 7 - Pool Size: 2\n",
    "<img src=\"Scripts/Parte2/72.png\" style=\"width: 300px;\"/>\n",
    "#### Convolucion: 7 - Pool Size: 4\n",
    "<img src=\"Scripts/Parte2/74.png\" style=\"width: 300px;\"/>\n",
    "#### Convolucion: 9 - Pool Size: 2\n",
    "<img src=\"Scripts/Parte2/92.png\" style=\"width: 300px;\"/>\n",
    "#### Convolucion: 9 - Pool Size: 4\n",
    "<img src=\"Scripts/Parte2/94.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "#### Convolucion: 5/7/9 - Pool Size: 2\n",
    "<img src=\"Scripts/Parte2/222.png\" style=\"width: 300px;\"/>\n",
    "#### Convolucion: 5/9 - Pool Size: 2\n",
    "<img src=\"Scripts/Parte2/22.png\" style=\"width: 300px;\"/>\n",
    "#### Convolucion: 5/7/9 - Pool Size: 4\n",
    "<img src=\"Scripts/Parte2/444.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "#### Convolucion: 5/7/9 - Pool Size: 2/4\n",
    "<img src=\"Scripts/Parte2/222444.png\" style=\"width: 300px;\"/>\n",
    "#### Convolucion: 5/9 - Pool Size: 2/4\n",
    "<img src=\"Scripts/Parte2/22444.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "Luego de ver estos gráficos se puede notar claramente como el pooling afecta de manera directa al rendimiento de la red convolucional, siendo que los pooling mayores tengan mejor convergencia en términos de perdida.\n",
    "\n",
    "## E)\n",
    "\n",
    "Para esta sección se utilizó lo realizado en la sección anterior dada la modificación de **SOLO** la cantidad de ambas capas, los valores de tamaño. Luego se recepcionaron los tiempos y estos fueron gráficados individualmente como en conjunto. Se utilizaron para la primera capa los valores de **16, 32, 64**, mientras que para la segunda capa los valores de **128, 256, 512**.\n",
    "\n",
    "**NOTAR** Una gran cantidad de estos datos se perdieron en un corte de energìa, dado que no conociamos la posibilidad de realizar model.save() no pudimos representar la tabla en su completitud, sin embargo, en tiempo de ejecuciòn logramos ver que las arquitecturas que mejor rendimiento tenian eran aquellas que consideraban cantidad de 32 filtros en su capa inicial.\n",
    "\n",
    "|Capa 1| Capa 2| Loss  | Accuracy |\n",
    "|:-----|:------|:------|----------|\n",
    "| 16   | 128   | 0.7678| 0.7775   |\n",
    "| 16   | 256   | 1.1532| 0.6180   |\n",
    "| 32   | 256   | 0.6139| 0.8244   |\n",
    "| 64   | 256   | 1.0439| 0.6810   |\n",
    "\n",
    "## F)\n",
    "\n",
    "Finalmente la nueva arquitectura que utilizaremos \n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), border_mode='same', activation='relu', input_shape=(n_channels, size_h, size_w)))\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(128, (3, 3), border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()\n",
    "```\n",
    "<center>\n",
    "```\n",
    "|-----------------------------|-------------------|----------|\n",
    "| Layer (type)                | Output Shape      | Param #  |\n",
    "|-----------------------------|-------------------|----------|\n",
    "|conv2d_1 (Conv2D)            |(None, 32, 32, 32) |896       |\n",
    "|conv2d_2 (Conv2D)            |(None, 32, 30, 30) |9248      |\n",
    "|max_pooling2d_1 (MaxPooling2)|(None, 32, 15, 15) |0         |\n",
    "|conv2d_3 (Conv2D)            |(None, 128, 15, 15)|36992     |\n",
    "|conv2d_4 (Conv2D)            |(None, 128, 13, 13)|147584    |\n",
    "|max_pooling2d_2 (MaxPooling2)|(None, 512, 6, 6)  |0         |\n",
    "|flatten_1 (Flatten)          |(None, 32768)      |0         |\n",
    "|dense_1 (Dense)              |(None, 20)         |92180     |\n",
    "|dense_2 (Dense)              |(None, 10)         |210       |\n",
    "```\n",
    "</center>\n",
    "\n",
    "> Total params: 287,110\n",
    "\n",
    "> Trainable params: 287,110\n",
    "\n",
    "> Non-trainable params: 0\n",
    "\n",
    "## G)\n",
    "\n",
    "De las entrenadas, se decide utilizar la convolución 5 con pooling 4. Luego de generar el modelo, se utiliza la propiedad layers que retorna las capas de la red y se selecciona la primera, a lo que se le utiliza la propiedad *get_weight*.\n",
    "```python\n",
    "first = model.layers[0]\n",
    "weights = np.array(first.get_weights())\n",
    "```\n",
    "Luego dado que estamos corriendo el código en un script aparte, presentamos el shape de los pesos y un pequeño estracto de ellos.\n",
    "\n",
    "> (5, 5, 3, 16)\n",
    "\n",
    "<img src=\"Scripts/Parte2/pesos.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "Luego seleccionamos una imagen al azar y utilizando *Keras.backend* vemos las acciones de los filtros sobre la imagen en la capa de salida.\n",
    "\n",
    "<img src=\"Scripts/Parte2/filter.png\" style=\"width: 100px;\"/>\n",
    "\n",
    "...\n",
    "\n",
    "## H)\n",
    "\n",
    "Hemos corrido nuestra red y los resultados son bastante acogedores dado que las clases son reconocidas correctamente en su primera opción, lo que si resaltamos es que el número **2**, por su forma tiende a ser el más confundido con respecto a los demás.\n",
    "```\n",
    "5088/5099 [============================>.] - ETA: 0s Class 0 gets:  0 and 6\n",
    "4149/4149 [==============================] - 16s     Class 1 gets:  1 and 2\n",
    "2880/2882 [============================>.] - ETA: 0s Class 2 gets:  2 and 1\n",
    "2523/2523 [==============================] - 9s      Class 3 gets:  3 and 0\n",
    "2384/2384 [==============================] - 9s      Class 4 gets:  4 and 2\n",
    "1977/1977 [==============================] - 7s      Class 5 gets:  5 and 2\n",
    "2016/2019 [============================>.] - ETA: 0s Class 6 gets:  6 and 1\n",
    "1660/1660 [==============================] - 6s      Class 7 gets:  7 and 2\n",
    "1595/1595 [==============================] - 6s      Class 8 gets:  8 and 2\n",
    "1744/1744 [==============================] - 6s      Class 9 gets:  9 and 2\n",
    "```\n",
    "## I)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

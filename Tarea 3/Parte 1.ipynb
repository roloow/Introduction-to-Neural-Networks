{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de sentimientos usando RNN\n",
    "\n",
    "Hoy en día, una aplicación relevante de las redes neuronales recurrentes es el modelamiento de texto y lenguaje natural. En esta sección abordaremos el problema de procesar el texto contenido en comentarios u opiniones (*review*) sobre una película para determinar su polaridad, es decir, determinar si reﬂeja un sentiemiento positivo o negativo. Usaremos el *Large Movie Review Dataset*, también conocido como *IMDB dataset* que contiene **50000 comentarios** de películas etiquetadas como buenas o malas (50%-50% train-testing).\n",
    "\n",
    "------------------\n",
    "\n",
    "## Librerias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "### Carga de Datos\n",
    "\n",
    "Se utiliza la base de datos de imdb, la cual mediante la funcion *load_data* produce conjuntos separados por tuplas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"B:\\Programas\\Google Drive\\USM\\Redes Neuronales\\Tarea 3\\datasets\\imdb.npz\",seed=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-------------\n",
    "### Estudio de distribución\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos los datos cargados y listos para ser analizados, veremos su forma, la cantidad de clases que tiene, el número de palabras. De aquí esperamos que el contenido sea de *(50000, None)* dadas las especificaciones en la [Documentación de keras imdb](https://keras.io/datasets/), además estas podrán ser *\"buenas\"* o *\"malas\"* lo que nos indice a pensar que será un comportamiento binario el número de clases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "(50000,) \n",
      "(50000,)\n",
      "\n",
      "Clases:\n",
      "[0 1]\n",
      "\n",
      "Review lenght: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa3dae30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print \"Training data:\\n\", X.shape, \"\\n\", y.shape\n",
    "\n",
    "print \"\\nClases:\\n\", np.unique(y)\n",
    "\n",
    "print \"\\nReview lenght: \"\n",
    "result = map(len, X)\n",
    "plt.boxplot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar la alta concentración en comentarios con menos de 500 palabras, teniendo una media de *234.75892* palabras y una desviación estandar de *172.91149*. (Ambos datos obtenidos a través de **np.mean** y **np.std**). Ahora bien para analizar las palabras aprovechares la indexación que viene en este dataset. Se muestran algunos gráficos que corresponden a los datos obtenidos mediante **np.unique(ds, return_counts=True)**. Tomando en cuenta que las cantidades de palabras en estos ejemplos son las siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de palabras distintas: 88585\n",
      "\n",
      "Cantidad de palabras totales: 11737946\n"
     ]
    }
   ],
   "source": [
    "print \"\\nCantidad de palabras distintas:\", len(np.unique(np.hstack(X)))\n",
    "print \"\\nCantidad de palabras totales:\", len(np.hstack(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: *Todos los gráficos a continuación fueron creados mediante el script **frecuencia.py** de los archivos de **scripts** *.\n",
    "\n",
    "<img src=\"images/fig1.png\" style=\"width: 500px;\" name=\"Grafico 1\"/>\n",
    "<center>\n",
    "Gráfico 1: AxisY Frecuencia vs AxisX Indice de palabra\n",
    "</center>\n",
    "\n",
    "Dentro de todo, no se puede establecer un mayor criterio dada la alta cantidad de datos, lo que si podemos notar es que se produce una especia de linea convergente hacia valores menores con los índices mayores mientras que los índices menores obtienen una frecuencia muy por sobre el resto.\n",
    "\n",
    "<img src=\"images/zoom1.png\" style=\"width: 500px;\" name=\"Grafico 2\"/>\n",
    "<center>\n",
    "Gráfico 1.1: Zoom del gráfico 1\n",
    "</center>\n",
    "\n",
    "Si miramos el mismo gráficos pero un poco más cercano a los valores de índice entre *1-1500*, se puede aprecia la curva mencionada que tiene una suerte de $ \\frac{1}{x} $. Esto nos lleva a que se produzca una eventual **ley de Zipf**. [(Ver más)](https://es.wikipedia.org/wiki/Ley_de_Zipf) Esta ley menciona que la distribución del lenguaje puede aproximarse a\n",
    "\n",
    "\\begin{equation}\n",
    "P_n  \\to  \\frac{1}{n^a}\n",
    "\\end{equation}\n",
    "\n",
    "donde $P_n$ es la frecuencia de la n-ésima palabra más frecuente y $a$ es un número real positivo, en general ligeramente superior a 1. Un gráfico en representación logarítmica de la ley es el siguiente:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/d/da/Zipf_30wiki_es_labels.png\" style=\"width: 500px;\" name=\"Grafico 3\"/>\n",
    "<center>\n",
    "Imagen 1: Ley de Zipf\n",
    "</center>\n",
    "\n",
    "Como nuestra distribución presentaba estas caracteristicas quisimos gráficar nuestros datos de manera logarítmica obteniendo:\n",
    "\n",
    "<img src=\"images/log1.png\" style=\"width: 500px;\" name=\"Grafico 4\"/>\n",
    "<center>\n",
    "Gráfico 1.2: Representación logarítmica del gráfico 1\n",
    "</center>\n",
    "\n",
    "Sin lugar a dudas, el gráfico presenta características abrumadores, con un pick inicial y una alta densidad al final, pero dejando estos conceptos de lado y analizando la base del gráfico podemos notar que si se aprecia la curva esperable.\n",
    "\n",
    "*Ahora bien, ¿cómo cambian estas características al separar los textos de acuerdo a sus clases?*\n",
    "\n",
    "Lo que se esperaría en este análisis es que no debiese cambiar, debido a que la Ley de Zipf habla sobre una distribución del lenguaje más que de las palabras especificas que pueden conllevar un sentimiento por sobre otro. **Nota** nuevamente los gráficos fueron obtenidos a través del script *frecuencia.py*.\n",
    "\n",
    "<img src=\"images/fig2.png\" style=\"width: 500px;\" name=\"Grafico 5\"/>\n",
    "<center>\n",
    "Gráfico 2: Representación de los datos separados por clase\n",
    "</center>\n",
    "\n",
    "<img src=\"images/zoom4.png\" style=\"width: 500px;\" name=\"Grafico 6\"/>\n",
    "<center>\n",
    "Gráfico 2.1: Zoom del gráfico 2\n",
    "</center>\n",
    "\n",
    "<img src=\"images/log2.png\" style=\"width: 500px;\" name=\"Grafico 7\"/>\n",
    "<center>\n",
    "Gráfico 2.2: Representación logarítmica del gráfico 2\n",
    "</center>\n",
    "\n",
    "Tal como se esperaba, los resultados fueron prácticamente los mismos. La única conclusión feaciente que podemos realizar luego de hacer esta comparativa es que las palabras indexadas como 0, que equivalen a las palabras desconocidas, están relacionadas a comentarios negativos.\n",
    "\n",
    "---------------------------\n",
    "\n",
    "### Carga de datos acotada\n",
    "\n",
    "Dado que la carga de datos se basa en un criterio de *most used words*, basta con cargar una cantidad de datos más acotada para que se cumpla el requerimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train2, y_train2), (X_test2, y_test2) = imdb.load_data(path=\"B:/Programas/Google Drive/USM/Redes Neuronales/Tarea 3/datasets/imdb.npz\", num_words=3000, seed=15)\n",
    "\n",
    "X_train2 = sequence.pad_sequences(X_train2, maxlen=500)\n",
    "X_test2 = sequence.pad_sequences(X_test2, maxlen=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que se están utilizando una cantidad de palabras más acotadas, y que los comentarios fueron truncados a un máximo de 500 palabras, existirán algunas que no tengan estas caracteristicas, y como mencionamos en un momentos las palabras con índice 0, son las irreconocibles, por lo tanto cuando tengamos un diccionario con menor cantidad de palabras a su haber, las consiguientes al mismo tendrán un valor desconocido (*0*).\n",
    "\n",
    "-------------------\n",
    "\n",
    "### Red LSTM\n",
    "\n",
    "Al utilizar la funcionalidad *Embeding* de Keras, sabemos que la salida de la primera capa será del tamaño del vector de salida que fijemos \"*EVL*\" (*Embeding vector length*) por la cantidad de palabras que posea el diccionario. Para este caso usaremos una configuración **32x500**. La red será entrenada en el script *LSTM.py* y traida acá a través del comando *save*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           96000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 149,301\n",
      "Trainable params: 149,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "TOP_WORDS = 3000\n",
    "EVL = 32\n",
    "MAX_WORDS = 500\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(TOP_WORDS, EVL, input_length=MAX_WORDS))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de ser entrenada el modelo presenta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.752%\n"
     ]
    }
   ],
   "source": [
    "model = load_model('B:/Programas/Google Drive/USM/Redes Neuronales/Tarea 3/scripts/lstm.h5')\n",
    "\n",
    "scores = model.evaluate(X_test2, y_test2, verbose=0)\n",
    "print(\"Accuracy: {0}%\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "### Variación de Embedding\n",
    "\n",
    "La variación que se presenta al realizar un cambio de embedding de 32 a 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.724%\n"
     ]
    }
   ],
   "source": [
    "model = load_model('B:/Programas/Google Drive/USM/Redes Neuronales/Tarea 3/scripts/lstmv2.h5')\n",
    "\n",
    "scores = model.evaluate(X_test2, y_test2, verbose=0)\n",
    "print(\"Accuracy: {0}%\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era esperable, aumentar la longitud del vector beneficia al entrenamiento debido a que la red tiene una mayor cantidad de caracteristicas para poder analizar.\n",
    "\n",
    "-------------------\n",
    "\n",
    "### Variación de Top Words\n",
    "\n",
    "Para poder hacer una buena comparativa se entrenó una red de 64 *EVL* con distintas cantidades de palabras y luego se gráficaron con respecto a su exactitud de predicción. Las variaciones fueron de a *1000* entre los rangos *1000-8000*.\n",
    "\n",
    "<img src=\"images/tp.png\" style=\"width: 500px;\" name=\"Grafico 8\"/>\n",
    "<center>\n",
    "Gráfico 3: Top Words vs Accuracy\n",
    "</center>\n",
    "\n",
    "Con este gráfico podemos notar como no existe una real correlación, si podemos decir que un número acertado de palabras es mayor a 3000, dado que tiende a converger en un valor superior a 85% accuracy. Esto se debe en gran medida a que una amplia variedad de palabras pueden permitir a la red comprender mejor los conjuntos sin embargo como bien estas palabras estan ordenadas por frecuencia de uso, a medida que más son las palabras en menos casos ayudan. Es por esto que se llega a una conclusión parecida a lo que muestra el gráfico, dado que es necesario tener un diccionario decente de palabras aunque tener uno excesivamente grande no necesariamente ayudará.\n",
    "\n",
    "-------------\n",
    "\n",
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.80799999999999\n"
     ]
    }
   ],
   "source": [
    "model = load_model('B:/Programas/Google Drive/USM/Redes Neuronales/Tarea 3/scripts/dropout.h5')\n",
    "scores = model.evaluate(X_test2, y_test2, verbose=0)\n",
    "print(\"Accuracy: {0}\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de realizar la evaluación podemos decir que utilizar *Dropout* no es beneficioso para el modelo que utilizamos aún cuando, se esperaba una mejora. El dropout, al ser una técnica de regularización, debiese beneficiar el entrenamiento porque evita problemas de overfitting, sin embargo la caida de *accuracy* en este caso especifico puede estar de la mano de una sobre regularización para un corto periodo de entrenamiento, es decir, de haber entrenado una mayor cantidad de epochs el resultado habría sido una mejora del anterior. (*Supuesto*)\n",
    "\n",
    "--------------\n",
    "\n",
    "### Propuesto\n",
    "\n",
    "Dados los análisis anteriores, para una baja cantidad de epochs no nos conviene agregar un *Dropout*, nos conviene utilizar un *EVL* de 64 y usaremos 7000 palabras frecuentes con longitud de 500.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 64)           448000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 514,101\n",
      "Trainable params: 514,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 399s - loss: 0.4733 - acc: 0.7804 - val_loss: 0.3536 - val_acc: 0.8474\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 392s - loss: 0.2850 - acc: 0.8860 - val_loss: 0.3487 - val_acc: 0.8538\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 396s - loss: 0.2262 - acc: 0.9128 - val_loss: 0.3355 - val_acc: 0.8731\n",
      "Accuracy: 87.30799999999999%\n"
     ]
    }
   ],
   "source": [
    "TOP_WORDS = 7000\n",
    "EVL = 64\n",
    "MAX_WORDS = 500\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"B:/Programas/Google Drive/USM/Redes Neuronales/Tarea 3/datasets/imdb.npz\", num_words=TOP_WORDS, seed=15)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(TOP_WORDS, EVL, input_length=MAX_WORDS))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "model.save('propuesta.h5')\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {0}%\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante entrenamiento vemos que esta propuesta es la que obtiene el mejor grado de *accuracy* con una menor *pérdida* de todos los casos utilizados llegando a **91.28%** de *acc*. Luego al ser evaluada en el conjunto de testing se llega a un *Accuracy* final de **87.3%**. Aún así, intentaremos crear una segunda configuración la cual tenga una capa extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 64)           448000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               66000     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               25250     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 539,501\n",
      "Trainable params: 539,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 436s - loss: 0.4422 - acc: 0.7871 - val_loss: 0.3178 - val_acc: 0.8665\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 447s - loss: 0.2607 - acc: 0.8956 - val_loss: 0.3087 - val_acc: 0.8728\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 445s - loss: 0.2206 - acc: 0.9147 - val_loss: 0.3204 - val_acc: 0.8702\n",
      "Accuracy: 87.024%\n"
     ]
    }
   ],
   "source": [
    "TOP_WORDS = 7000\n",
    "EVL = 64\n",
    "MAX_WORDS = 500\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path=\"B:/Programas/Google Drive/USM/Redes Neuronales/Tarea 3/datasets/imdb.npz\", num_words=TOP_WORDS, seed=15)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(TOP_WORDS, EVL, input_length=MAX_WORDS))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "model.save('propuesta2.h5')\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {0}%\".format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente en periodo de entrenamiento, agregar una capa mejoró el rendimiento, sin embargo a la hora de evaluación bajo un poco. Una propuesta extra que hacemos es realizar un entrenamiento de 5 epochs sin embargo por motivos *temporales* no podemos llevarla a cabo. Aún así, notamos como nuestras propuestas han mejorado el rendimiento original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
